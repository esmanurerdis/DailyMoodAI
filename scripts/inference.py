from __future__ import annotations

from typing import Dict, Tuple, List
from functools import lru_cache
from pathlib import Path
from time import perf_counter
import json
import re

# Route/cost logger
from scripts.route_logger import log_call

# 1) √áEVƒ∞Rƒ∞ MarianMT 
_SUPPORTED = {
    "tr": "Helsinki-NLP/opus-mt-tr-en",
    "de": "Helsinki-NLP/opus-mt-de-en",
    "es": "Helsinki-NLP/opus-mt-es-en",
    "en": None,  # ƒ∞ngilizce gelirse model gerekmez
}

@lru_cache(maxsize=None)
def _get_translation_pipe(src_lang: str):
    """Kaynak dil i√ßin √ßeviri pipeline'ƒ±nƒ± hazƒ±rla ve cache et."""
    src = (src_lang or "").lower()
    if src == "en":
        return None
    from transformers import pipeline
    model_id = _SUPPORTED.get(src)
    if model_id is None:
        return None
    # CPU kullanƒ±mƒ±: device=-1
    return pipeline("translation", model=model_id, device=-1)

def translate_to_en(text: str, src_lang: str) -> str:
    """Metni ƒ∞ngilizceye √ßevir. Desteklenmeyen dil gelirse olduƒüu gibi d√∂nd√ºr√ºr."""
    if not text:
        return ""
    pipe = _get_translation_pipe(src_lang)
    if pipe is None:
        # ƒ∞ngilizce veya desteklenmeyen dil ‚Üí √ßevirmeden d√∂nd√ºr
        return text

    # S√ºre √∂l√ß + √ßeviri
    start = perf_counter()
    out = pipe(text, max_length=256)
    latency = perf_counter() - start

    hyp = out[0]["translation_text"]

    # Kaba token tahmini: bo≈ülukla ayrƒ±lmƒ±≈ü kelime sayƒ±sƒ±
    tokens = len((text or "").split())

    # Lokal model ‚Üí cost=0.0
    log_call(model=f"translation-{(src_lang or '').lower()}-en", tokens=tokens, cost=0.0, latency=latency)
    return hyp

# EN mood -> TR kar≈üƒ±lƒ±k
_EN2TR = {
    "sad": "√ºzg√ºn",
    "anxious": "kaygƒ±lƒ±",
    "happy": "mutlu",
    "tired": "yorgun",
}

# Basit ƒ∞ngilizce anahtar kelime listeleri
_KW = {
    "tired":   {"tired", "sleepy", "exhausted", "fatigued", "weary", "drained"},
    "anxious": {"anxious", "nervous", "worried", "stressed", "panic", "tense"},
    "sad":     {"sad", "unhappy", "upset", "depressed", "down", "miserable"},
    "happy":   {"happy", "good", "great", "glad", "joy", "love", "excited", "awesome", "fine", "okay", "ok"},
}

def _normalize_en(s: str) -> List[str]:
    s = (s or "").lower()
    s = re.sub(r"[^a-z\s]", " ", s)  # basit temizlik
    return s.split()

def _rule_based_mood_en(text_en: str) -> str:
    """√áok basit, anla≈üƒ±lƒ±r kural seti (junior seviye)."""
    toks = set(_normalize_en(text_en))

    # 1) Fiziksel yorgunluk i≈üaretleri varsa √∂nce onu se√ß
    if toks & _KW["tired"]:
        return "tired"
    # 2) Kaygƒ± i≈üaretleri
    if toks & _KW["anxious"]:
        return "anxious"

    # 3) Mutlu vs √ºzg√ºn sayƒ±mƒ±
    happy_hits = len(toks & _KW["happy"])
    sad_hits   = len(toks & _KW["sad"])
    if happy_hits > sad_hits:
        return "happy"
    if sad_hits > happy_hits:
        return "sad"

    # 4) N√∂tr: pozitif varsayƒ±m
    return "happy"

@lru_cache(maxsize=None)
def _load_suggestions(path: str = "data/suggestions.json") -> List[Dict]:
    p = Path(path)
    with p.open("r", encoding="utf-8") as f:
        return json.load(f)

def suggest_mood_and_advice(user_text: str, lang: str = "tr") -> Tuple[str, str, str]:
    """
    Girdi: user_text + dili
    √áƒ±kƒ±≈ü: (mood_tr, suggestion_tr, translated_en)
    """
    # 1) ƒ∞ngilizce normalize et
    text_en = user_text if (lang or "").lower() == "en" else translate_to_en(user_text, lang)

    # 2) Mood tespit (EN)
    mood_en = _rule_based_mood_en(text_en)

    # 3) TR kar≈üƒ±lƒ±k + √∂neriyi getir
    mood_tr = _EN2TR[mood_en]
    suggestions = _load_suggestions()
    suggestion_tr = next(
        (row["suggestion"] for row in suggestions if row.get("mood") == mood_tr),
        "Kendine nazik ol; kƒ±sa bir mola ver. üòä"
    )
    return mood_tr, suggestion_tr, text_en

# 3) SENTIMENT (ger√ßek model ‚Äì √ßok dilli)
# Model: nlptown/bert-base-multilingual-uncased-sentiment
# √áƒ±ktƒ±yƒ± 1‚Äì5 yƒ±ldƒ±zdan pos/neg/neu'ya √ßeviriyoruz.
@lru_cache(maxsize=1)
def _get_sentiment_pipe():
    from transformers import pipeline
    model_id = "nlptown/bert-base-multilingual-uncased-sentiment"
    return pipeline("sentiment-analysis", model=model_id, device=-1)

def predict_sentiment(text: str, lang: str = "tr") -> Dict[str, float]:
    """
    D√∂nen s√∂zl√ºk:
      {"label": "pos|neg|neu", "proba": 0.0-1.0}
    """
    if not text:
        return {"label": "neu", "proba": 0.0}

    pipe = _get_sentiment_pipe()

    # S√ºre √∂l√ß + tahmin
    start = perf_counter()
    result = pipe(text[:512])[0] 
    latency = perf_counter() - start

    # Token tahmini
    tokens = len((text or "").split())

    # Logla (lokal model, cost=0.0)
    log_call(model="sentiment-nlptown-bert", tokens=tokens, cost=0.0, latency=latency)

    label = result["label"]
    score = float(result["score"])
    try:
        stars = int(label.split()[0])
    except Exception:
        return {"label": "neu", "proba": score}

    if stars in (4, 5):
        return {"label": "pos", "proba": score}
    if stars == 3:
        return {"label": "neu", "proba": score}
    return {"label": "neg", "proba": score}
